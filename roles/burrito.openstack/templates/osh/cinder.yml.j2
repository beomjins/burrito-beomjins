---
images:
  tags:
    db_init: "{{ docker_image_repo }}/jijisa/heat:yoga-ubuntu_focal"
    cinder_db_sync: "{{ docker_image_repo }}/jijisa/cinder:skb-yoga-ubuntu_jammy"
    db_drop: "{{ docker_image_repo }}/jijisa/heat:yoga-ubuntu_focal"
    rabbit_init: "{{ docker_image_repo }}/library/rabbitmq:3.11-management"
    ks_user: "{{ docker_image_repo }}/jijisa/heat:yoga-ubuntu_focal"
    ks_service: "{{ docker_image_repo }}/jijisa/heat:yoga-ubuntu_focal"
    ks_endpoints: "{{ docker_image_repo }}/jijisa/heat:yoga-ubuntu_focal"
    cinder_api: "{{ docker_image_repo }}/jijisa/cinder:skb-yoga-ubuntu_jammy"
    bootstrap: "{{ docker_image_repo }}/jijisa/heat:yoga-ubuntu_focal"
    cinder_scheduler: "{{ docker_image_repo }}/jijisa/cinder:skb-yoga-ubuntu_jammy"
    cinder_volume: "{{ docker_image_repo }}/jijisa/cinder:skb-yoga-ubuntu_jammy"
    cinder_volume_usage_audit: "{{ docker_image_repo }}/jijisa/cinder:skb-yoga-ubuntu_jammy"
    cinder_storage_init: "{{ docker_image_repo }}/openstackhelm/ceph-config-helper:latest-ubuntu_focal"
    cinder_backup: "{{ docker_image_repo }}/jijisa/cinder:skb-yoga-ubuntu_jammy"
    cinder_backup_storage_init: "{{ docker_image_repo }}/openstackhelm/ceph-config-helper:latest-ubuntu_focal"
    dep_check: "{{ quay_image_repo }}/airshipit/kubernetes-entrypoint:v1.0.0"

pod:
  security_context:
    cinder_api:
      container:
        cinder_api:
          runAsUser: 0
          readOnlyRootFilesystem: false
{% if "netapp" in storage_backends %}
    cinder_volume:
      container:
        cinder_volume:
          capabilities:
            add:
              - SYS_ADMIN
          readOnlyRootFilesystem: false
{% endif %}
  replicas:
    api: {{ pod.replicas }}
    backup: {{ pod.replicas }}
    scheduler: {{ pod.replicas }}
    volume: {{ pod.replicas }}

bootstrap:
  volume_types:
{% if "ceph" in storage_backends %}
    rbd1:
      volume_backend_name: rbd1
      access_type: "private"
{% endif %}
{% if "netapp" in storage_backends %}
{% for n in netapp %}
    {{ n.name }}:
      volume_backend_name: {{ n.name }}
      access_type: "private"
      dataLIF: "{{ n.dataLIF }}"
      shares:
{% for share in n.shares %}
        - "{{ share }}"
{% endfor %}
{% endfor %}
{% endif %}

network:
  api:
    ingress:
      annotations:
        nginx.ingress.kubernetes.io/backend-protocol: "https"
conf:
  db_acl:
    enabled: true
  software:
    apache2:
      binary: apache2
      start_parameters: -DFOREGROUND
      site_dir: /etc/apache2/sites-enabled
      conf_dir: /etc/apache2/conf-enabled
      mods_dir: /etc/apache2/mods-available
      a2enmod:
        - ssl
      a2dismod: null
{% raw %}
  mpm_event: |
    <IfModule mpm_event_module>
      ServerLimit         1024
      StartServers        32
      MinSpareThreads     32
      MaxSpareThreads     256
      ThreadsPerChild     25
      MaxRequestsPerChild 128
      ThreadLimit         720
    </IfModule>
  wsgi_cinder: |
    {{- $portInt := tuple "volumev3" "internal" "api" $ | include "helm-toolkit.endpoints.endpoint_port_lookup" }}
    Listen {{ $portInt }}
    <VirtualHost *:{{ $portInt }}>
      ServerName {{ printf "%s.%s.svc.%s" "cinder-api" .Release.Namespace .Values.endpoints.cluster_domain_suffix }}
      WSGIDaemonProcess cinder-api processes=1 threads=1 user=cinder display-name=%{GROUP}
      WSGIProcessGroup cinder-api
      WSGIScriptAlias /  /var/www/cgi-bin/cinder/cinder-wsgi
      WSGIApplicationGroup %{GLOBAL}
      WSGIPassAuthorization On
      AllowEncodedSlashes On
      <IfVersion >= 2.4>
        ErrorLogFormat "%{cu}t %M"
      </IfVersion>
      SetEnvIf X-Forwarded-For "^.*\..*\..*\..*" forwarded
      ErrorLog /dev/stdout
      CustomLog /dev/stdout combined env=!forwarded
      CustomLog /dev/stdout proxy env=forwarded

      SSLEngine on
      SSLCertificateFile      /etc/cinder/certs/tls.crt
      SSLCertificateKeyFile   /etc/cinder/certs/tls.key
      SSLProtocol             all -SSLv3 -TLSv1 -TLSv1.1
      SSLCipherSuite          ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256
      SSLHonorCipherOrder     on
    </VirtualHost>
{% endraw %}
  ceph:
    admin_keyring: {{ ceph_admin_key }}
    pools:
      backups:
        replication: {{ ceph_pool_default_size }}
        crush_rule: replicated_rule
        chunk_size: 8
        app_name: rbd
      volumes:
        replication: {{ ceph_pool_default_size }}
        crush_rule: replicated_rule
        chunk_size: 8
        app_name: rbd
  cinder:
    DEFAULT:
      glance_ca_certificates_file: /etc/cinder/certs/ca.crt
      debug: true
      enable_force_upload: true
      allow_direct_url_schemes: cinder
      cinder_internal_tenant_project_id: internal_cinder
      cinder_internal_tenant_user_id: internal_cinder
      enabled_backends: "{{ cinder.enabled_backends }}"
      default_volume_type: "{{ cinder.default_volume_type }}"
{% if "ceph" in storage_backends and enable_cinder_backup %}
      backup_driver: cinder.backup.drivers.ceph.CephBackupDriver
      backup_ceph_user: cinder-backup
      backup_ceph_pool: backups
{% endif %}
      use_default_quota_class: true
      quota_driver: cinder.quota.DbQuotaDriver
      quota_consistencygroups: -1
      quota_backup_gigabytes: -1
      quota_backups: -1
      quota_gigabytes: -1
      quota_groups: -1
      quota_snapshots: -1
      quota_volumes: -1
    keystone_authtoken:
      cafile: /etc/cinder/certs/ca.crt
    key_manager:
      backend: barbican
    nova:
      auth_version: v3
      auth_type: password
      cafile: /etc/cinder/certs/ca.crt
    oslo_messaging_rabbit:
      ssl: true
      ssl_ca_file: /etc/rabbitmq/certs/ca.crt
      ssl_cert_file: /etc/rabbitmq/certs/tls.crt
      ssl_key_file: /etc/rabbitmq/certs/tls.key
  backends:
{% if "ceph" in storage_backends %}
    rbd1:
      volume_driver: cinder.volume.drivers.rbd.RBDDriver
      volume_backend_name: rbd1
      rbd_ceph_conf: "/etc/ceph/ceph.conf"
      rbd_flatten_volume_from_snapshot: false
      rbd_max_clone_depth: 5
      rbd_store_chunk_size: 8
      rados_connect_timeout: -1
      rbd_user: "cinder"
      rbd_pool: "volumes"
      rbd_secret_uuid: "{{ ceph_secret_uuid }}"
      rbd_exclusive_cinder_pool: true
{% else %}
    rbd1: null
{% endif %}
{% if "netapp" in storage_backends %}
{% for n in netapp %}
    {{ n.name }}:
      #image_volume_cache_enabled: true
      volume_driver: cinder.volume.drivers.netapp.common.NetAppDriver
      volume_backend_name: {{ n.name }}
      netapp_storage_family: ontap_cluster
      netapp_storage_protocol: nfs
      netapp_vserver: "{{ n.svm }}"
      netapp_server_hostname: "{{ n.managementLIF }}"
      netapp_login: "{{ n.username }}"
      netapp_password: "{{ n.password }}"
      nfs_mount_options: "{{ n.nfsMountOptions }}"
      nfs_shares_config: "/etc/cinder/share_{{ n.name }}"
{% endfor %}
{% endif %}
endpoints:
  oslo_db:
    auth:
      admin:
        username: root
        password: {{ mariadb.admin_password }}
      cinder:
        username: cinder
        password: {{ cinder.password }}
  oslo_messaging:
    port:
      https:
        default: 15680
    auth:
      admin:
        username: rabbitmq
        password: {{ rabbitmq.password }}
      cinder:
        username: cinder
        password: {{ cinder.password }}
    statefulset: null
  identity:
    auth:
      admin:
        cacert: /etc/ssl/certs/openstack-helm.crt
        username: admin
        password: {{ os_admin_password }}
      cinder:
        cacert: /etc/ssl/certs/openstack-helm.crt
        username: cinder
        password: {{ cinder.password }}
      test:
        cacert: /etc/ssl/certs/openstack-helm.crt
    scheme:
      default: https
    port:
      api:
        default: 8443
        public: 8443
  image:
    scheme:
      default: https
    port:
      api:
        public: 8443
  image_registry:
    scheme:
      default: https
    port:
      api:
        public: 8443
  volume:
    name: cinder
    path:
      default: /v3/%(tenant_id)s
    port:
      api:
        public: 8443
  volumev3:
    name: cinder
    host_fqdn_override:
      default:
        tls:
          secretName: cinder-tls-api
          duration: {{ tls.duration }}
          renewBefore: {{ tls.renewBefore }}
          issuerRef:
            name: ca-issuer
            kind: ClusterIssuer
    scheme:
      default: https
      internal: https
    port:
      api:
        public: 8443
  ingress:
    port:
      ingress:
        default: 8443
{% if "ceph" not in storage_backends %}
# remove cinder-storage-init dependency
dependencies:
  static:
    api:
      jobs:
        - cinder-db-sync
        - cinder-ks-user
        - cinder-ks-endpoints
        - cinder-rabbit-init
    backup:
      jobs:
        - cinder-db-sync
        - cinder-ks-user
        - cinder-ks-endpoints
        - cinder-rabbit-init
    scheduler:
      jobs:
        - cinder-db-sync
        - cinder-ks-user
        - cinder-ks-endpoints
        - cinder-rabbit-init
    volume:
      jobs:
        - cinder-db-sync
        - cinder-ks-user
        - cinder-ks-endpoints
        - cinder-rabbit-init
    volume_usage_audit:
      jobs:
        - cinder-db-sync
        - cinder-ks-user
        - cinder-ks-endpoints
        - cinder-rabbit-init
{% endif %}
manifests:
  certificates: true
  deployment_backup: {{ enable_cinder_backup }}
  job_backup_storage_init: {{ enable_cinder_backup }}
  job_storage_init: {{ ("ceph" in storage_backends)|ternary('true', 'false') }}
...
